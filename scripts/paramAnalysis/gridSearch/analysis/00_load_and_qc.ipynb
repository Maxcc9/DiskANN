{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3d62a5",
   "metadata": {},
   "source": [
    "# 00 Load and QC\n",
    "\n",
    "Load the latest collected CSVs, validate uniqueness, and filter degenerate runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3c2e6",
   "metadata": {},
   "source": [
    "# 說明\n",
    "\n",
    "本 notebook 負責載入彙總 CSV，進行資料品質檢查與基礎過濾，並輸出 QC 表格與過濾後資料。\n",
    "\n",
    "## 主要輸入\n",
    "- `outputFiles/analyze/<COLLECT_PREFIX>/collected_stats_*.csv`\n",
    "- `outputFiles/analyze/<COLLECT_PREFIX>/collected_topk_*.csv`\n",
    "\n",
    "## 主要輸出\n",
    "- `tables/qc_summary.csv`\n",
    "- `tables/qc_basic_checks.csv`\n",
    "- `tables/qc_missingness.csv`\n",
    "- `tables/filtered_stats.csv`\n",
    "- `tables/filtered_out_stats.csv`\n",
    "- `figures/qc_hist_*.png`\n",
    "\n",
    "## 合理性檢查建議\n",
    "- `missing_stats_cols` / `missing_topk_cols` 應為 0\n",
    "- `runs_missing_in_topk` / `runs_missing_in_stats` 應接近 0\n",
    "- `filtered_out_stats.csv` 不應佔比過高（視實驗設計）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcd32cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.184903Z",
     "iopub.status.busy": "2026-01-07T13:15:13.184845Z",
     "iopub.status.idle": "2026-01-07T13:15:13.324355Z",
     "shell.execute_reply": "2026-01-07T13:15:13.324094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/collected_stats_sift01_20260107_195000.csv\n",
      "topk : /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/collected_topk_sift01_20260107_195000.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ANALYZE_DIR = Path('../outputFiles/analyze').resolve()\n",
    "REPORT_PREFIX = os.environ.get('REPORT_PREFIX', 'analysis_reports')\n",
    "COLLECT_PREFIX = os.environ.get('COLLECT_PREFIX', REPORT_PREFIX)\n",
    "REPORT_DIR = (ANALYZE_DIR / REPORT_PREFIX)\n",
    "COLLECT_DIR = (ANALYZE_DIR / COLLECT_PREFIX)\n",
    "STATS_CSV = None  # set to a specific file path if needed\n",
    "TOPK_CSV = None   # set to a specific file path if needed\n",
    "\n",
    "QC_REQUIRED_STATS_COLS = [\n",
    "    'run_prefix','search_L','search_W','search_K','search_T',\n",
    "    'recall_mean',\n",
    "]\n",
    "QC_REQUIRED_TOPK_COLS = ['run_prefix']\n",
    "QC_NUMERIC_CANDIDATES = [\n",
    "    'build_R','build_L','build_B','build_M',\n",
    "    'search_K','search_L','search_W','search_T',\n",
    "    'cache_size','vector_dim','dataset_size','num_queries',\n",
    "    'recall_mean','latency_p50_us','latency_p90_us','latency_p95_us','latency_p99_us','latency_p999_us',\n",
    "    'ios_p50','ios_p90','ios_p95','ios_p99',\n",
    "    'queue_depth_p50','queue_depth_p90','queue_depth_p95','queue_depth_p99',\n",
    "    'io_us_p50','io_us_p90','io_us_p95','io_us_p99',\n",
    "    'cpu_us_p50','cpu_us_p90','cpu_us_p95','cpu_us_p99',\n",
    "    'thread_util_p50','thread_util_p90','thread_util_p95','thread_util_p99',\n",
    "    'expanded_revisit_ratio','node_counts_top10_share','out_degree_p99',\n",
    "    'iostat_aqu-sz_mean',\n",
    "]\n",
    "QC_RECALL_THRESHOLD = float(os.environ.get('QC_RECALL_THRESHOLD', '0.7'))\n",
    "QC_RECALL_PCTL = float(os.environ.get('QC_RECALL_PCTL', '0'))\n",
    "QC_OUTLIER_Z = float(os.environ.get('QC_OUTLIER_Z', '4.0'))\n",
    "QC_MIN_COUNT = int(os.environ.get('QC_MIN_COUNT', '5'))\n",
    "QC_EXPECTED_NUM_QUERIES = int(os.environ.get('QC_EXPECTED_NUM_QUERIES', '0'))\n",
    "QC_PLOT = os.environ.get('QC_PLOT', '1') != '0'\n",
    "\n",
    "def pick_latest(pattern):\n",
    "    files = list(COLLECT_DIR.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f'No files matched: {pattern}')\n",
    "    # Choose by most recent modification time to ensure \"latest\" semantics\n",
    "    return max(files, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "def coerce_numeric(df, cols):\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def parse_run_prefix(value):\n",
    "    if not isinstance(value, str):\n",
    "        return {}\n",
    "    pattern = (\n",
    "        r\"_R(?P<build_R>\\d+)_L(?P<build_L>\\d+)_B(?P<build_B>\\d+)_M(?P<build_M>\\d+)\"\n",
    "        r\"_W(?P<search_W>\\d+)_L(?P<search_L>\\d+)_K(?P<search_K>\\d+)\"\n",
    "        r\"_cache(?P<cache_size>\\d+)_T(?P<search_T>\\d+)$\"\n",
    "    )\n",
    "    match = re.search(pattern, value)\n",
    "    if not match:\n",
    "        return {}\n",
    "    prefix = value[:match.start()]\n",
    "    search_id = ''\n",
    "    index_tag = ''\n",
    "    if prefix.startswith('S'):\n",
    "        parts = prefix.split('_', 1)\n",
    "        if parts and parts[0][1:].isdigit():\n",
    "            search_id = parts[0][1:]\n",
    "        if len(parts) > 1:\n",
    "            index_tag = parts[1]\n",
    "    else:\n",
    "        index_tag = prefix\n",
    "    data = match.groupdict()\n",
    "    data['search_id'] = search_id\n",
    "    data['index_tag'] = index_tag\n",
    "    return data\n",
    "\n",
    "stats_path = Path(STATS_CSV) if STATS_CSV else pick_latest('collected_stats_*.csv')\n",
    "topk_path = Path(TOPK_CSV) if TOPK_CSV else pick_latest('collected_topk_*.csv')\n",
    "\n",
    "print('stats:', stats_path)\n",
    "print('topk :', topk_path)\n",
    "\n",
    "stats_df = pd.read_csv(stats_path)\n",
    "topk_df = pd.read_csv(topk_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faae4f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.325247Z",
     "iopub.status.busy": "2026-01-07T13:15:13.325162Z",
     "iopub.status.idle": "2026-01-07T13:15:13.340478Z",
     "shell.execute_reply": "2026-01-07T13:15:13.340254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing stats cols: []\n",
      "missing topk cols : []\n",
      "rows stats: 3150\n",
      "rows topk : 3150\n",
      "duplicate run_prefix in stats: 0\n",
      "duplicate run_prefix in topk : 0\n",
      "runs with inconsistent search params: 0\n",
      "num_queries unique values: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_stats_rows</th>\n",
       "      <th>total_topk_rows</th>\n",
       "      <th>missing_stats_cols</th>\n",
       "      <th>missing_topk_cols</th>\n",
       "      <th>duplicate_stats_run_prefix</th>\n",
       "      <th>duplicate_topk_run_prefix</th>\n",
       "      <th>runs_with_inconsistent_search_params</th>\n",
       "      <th>num_queries_unique_values</th>\n",
       "      <th>num_queries_mismatch_expected</th>\n",
       "      <th>runs_missing_in_topk</th>\n",
       "      <th>runs_missing_in_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3150</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_stats_rows  total_topk_rows  missing_stats_cols  missing_topk_cols  \\\n",
       "0              3150             3150                   0                  0   \n",
       "\n",
       "   duplicate_stats_run_prefix  duplicate_topk_run_prefix  \\\n",
       "0                           0                          0   \n",
       "\n",
       "   runs_with_inconsistent_search_params  num_queries_unique_values  \\\n",
       "0                                     0                          1   \n",
       "\n",
       "   num_queries_mismatch_expected  runs_missing_in_topk  runs_missing_in_stats  \n",
       "0                              0                     0                      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic integrity checks and schema validation\n",
    "stats_df = stats_df.copy()\n",
    "topk_df = topk_df.copy()\n",
    "stats_df.columns = [str(c).strip() for c in stats_df.columns]\n",
    "topk_df.columns = [str(c).strip() for c in topk_df.columns]\n",
    "\n",
    "missing_stats_cols = [c for c in QC_REQUIRED_STATS_COLS if c not in stats_df.columns]\n",
    "missing_topk_cols = [c for c in QC_REQUIRED_TOPK_COLS if c not in topk_df.columns]\n",
    "print('missing stats cols:', missing_stats_cols)\n",
    "print('missing topk cols :', missing_topk_cols)\n",
    "\n",
    "numeric_cols = [c for c in QC_NUMERIC_CANDIDATES if c in stats_df.columns]\n",
    "stats_df = coerce_numeric(stats_df, numeric_cols)\n",
    "\n",
    "print('rows stats:', len(stats_df))\n",
    "print('rows topk :', len(topk_df))\n",
    "\n",
    "dup_stats = stats_df['run_prefix'].duplicated().sum() if 'run_prefix' in stats_df.columns else 0\n",
    "dup_topk = topk_df['run_prefix'].duplicated().sum() if 'run_prefix' in topk_df.columns else 0\n",
    "print('duplicate run_prefix in stats:', dup_stats)\n",
    "print('duplicate run_prefix in topk :', dup_topk)\n",
    "\n",
    "params_cols = [c for c in ['search_L','search_W','search_K','search_T'] if c in stats_df.columns]\n",
    "if params_cols and 'run_prefix' in stats_df.columns:\n",
    "    params_per_run = stats_df.groupby('run_prefix')[params_cols].nunique()\n",
    "    inconsistent = (params_per_run > 1).any(axis=1).sum()\n",
    "else:\n",
    "    inconsistent = 0\n",
    "print('runs with inconsistent search params:', inconsistent)\n",
    "\n",
    "if 'num_queries' in stats_df.columns:\n",
    "    num_queries_unique = stats_df['num_queries'].nunique()\n",
    "    expected_mismatch = 0\n",
    "    if QC_EXPECTED_NUM_QUERIES:\n",
    "        expected_mismatch = (stats_df['num_queries'] != QC_EXPECTED_NUM_QUERIES).sum()\n",
    "else:\n",
    "    num_queries_unique = 0\n",
    "    expected_mismatch = 0\n",
    "print('num_queries unique values:', num_queries_unique)\n",
    "if QC_EXPECTED_NUM_QUERIES:\n",
    "    print('num_queries mismatching expected:', expected_mismatch)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'column': stats_df.columns,\n",
    "    'missing_count': stats_df.isna().sum().values,\n",
    "    'missing_rate': stats_df.isna().mean().values,\n",
    "}).sort_values('missing_rate', ascending=False)\n",
    "\n",
    "if 'run_prefix' in stats_df.columns and 'run_prefix' in topk_df.columns:\n",
    "    stats_runs = set(stats_df['run_prefix'])\n",
    "    topk_runs = set(topk_df['run_prefix'])\n",
    "    missing_in_topk = sorted(stats_runs - topk_runs)\n",
    "    missing_in_stats = sorted(topk_runs - stats_runs)\n",
    "else:\n",
    "    missing_in_topk = []\n",
    "    missing_in_stats = []\n",
    "\n",
    "qc_basic_df = pd.DataFrame([\n",
    "    {\n",
    "        'total_stats_rows': len(stats_df),\n",
    "        'total_topk_rows': len(topk_df),\n",
    "        'missing_stats_cols': len(missing_stats_cols),\n",
    "        'missing_topk_cols': len(missing_topk_cols),\n",
    "        'duplicate_stats_run_prefix': int(dup_stats),\n",
    "        'duplicate_topk_run_prefix': int(dup_topk),\n",
    "        'runs_with_inconsistent_search_params': int(inconsistent),\n",
    "        'num_queries_unique_values': int(num_queries_unique),\n",
    "        'num_queries_mismatch_expected': int(expected_mismatch),\n",
    "        'runs_missing_in_topk': len(missing_in_topk),\n",
    "        'runs_missing_in_stats': len(missing_in_stats),\n",
    "    }\n",
    "])\n",
    "qc_basic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72721565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.341081Z",
     "iopub.status.busy": "2026-01-07T13:15:13.341012Z",
     "iopub.status.idle": "2026-01-07T13:15:13.356870Z",
     "shell.execute_reply": "2026-01-07T13:15:13.356646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered rows: 2955\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rows</th>\n",
       "      <th>filtered_rows</th>\n",
       "      <th>excluded_rows</th>\n",
       "      <th>low_recall_threshold</th>\n",
       "      <th>flag_search_L_lt_K</th>\n",
       "      <th>flag_search_L_lt_2W</th>\n",
       "      <th>flag_low_recall</th>\n",
       "      <th>flag_recall_out_of_range</th>\n",
       "      <th>flag_latency_p99_nonpositive</th>\n",
       "      <th>flag_latency_p999_nonpositive</th>\n",
       "      <th>flag_ios_p99_negative</th>\n",
       "      <th>flag_queue_depth_p99_negative</th>\n",
       "      <th>flag_io_us_p99_negative</th>\n",
       "      <th>flag_cpu_us_p99_negative</th>\n",
       "      <th>flag_thread_util_out_of_range</th>\n",
       "      <th>flag_vector_dim_nonpositive</th>\n",
       "      <th>flag_dataset_size_nonpositive</th>\n",
       "      <th>flag_num_queries_nonpositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3150</td>\n",
       "      <td>2955</td>\n",
       "      <td>195</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_rows  filtered_rows  excluded_rows  low_recall_threshold  \\\n",
       "0        3150           2955            195                   0.7   \n",
       "\n",
       "   flag_search_L_lt_K  flag_search_L_lt_2W  flag_low_recall  \\\n",
       "0                   0                    0              195   \n",
       "\n",
       "   flag_recall_out_of_range  flag_latency_p99_nonpositive  \\\n",
       "0                         0                             0   \n",
       "\n",
       "   flag_latency_p999_nonpositive  flag_ios_p99_negative  \\\n",
       "0                              0                      0   \n",
       "\n",
       "   flag_queue_depth_p99_negative  flag_io_us_p99_negative  \\\n",
       "0                              0                        0   \n",
       "\n",
       "   flag_cpu_us_p99_negative  flag_thread_util_out_of_range  \\\n",
       "0                         0                              0   \n",
       "\n",
       "   flag_vector_dim_nonpositive  flag_dataset_size_nonpositive  \\\n",
       "0                            0                              0   \n",
       "\n",
       "   flag_num_queries_nonpositive  \n",
       "0                             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering rules with explicit flags\n",
    "flags = pd.DataFrame(index=stats_df.index)\n",
    "\n",
    "if 'search_L' in stats_df.columns and 'search_K' in stats_df.columns:\n",
    "    flags['flag_search_L_lt_K'] = stats_df['search_L'] < stats_df['search_K']\n",
    "if 'search_L' in stats_df.columns and 'search_W' in stats_df.columns:\n",
    "    flags['flag_search_L_lt_2W'] = stats_df['search_L'] < 2 * stats_df['search_W']\n",
    "\n",
    "recall_threshold = QC_RECALL_THRESHOLD\n",
    "if 'recall_mean' in stats_df.columns and QC_RECALL_PCTL > 0:\n",
    "    recall_threshold = max(recall_threshold, stats_df['recall_mean'].quantile(QC_RECALL_PCTL))\n",
    "if 'recall_mean' in stats_df.columns:\n",
    "    flags['flag_low_recall'] = stats_df['recall_mean'] < recall_threshold\n",
    "    flags['flag_recall_out_of_range'] = (stats_df['recall_mean'] < 0) | (stats_df['recall_mean'] > 1)\n",
    "\n",
    "if 'latency_p99_us' in stats_df.columns:\n",
    "    flags['flag_latency_p99_nonpositive'] = stats_df['latency_p99_us'] <= 0\n",
    "if 'latency_p999_us' in stats_df.columns:\n",
    "    flags['flag_latency_p999_nonpositive'] = stats_df['latency_p999_us'] <= 0\n",
    "\n",
    "for col in ['ios_p99','queue_depth_p99','io_us_p99','cpu_us_p99']:\n",
    "    if col in stats_df.columns:\n",
    "        flags[f'flag_{col}_negative'] = stats_df[col] < 0\n",
    "if 'thread_util_p99' in stats_df.columns:\n",
    "    flags['flag_thread_util_out_of_range'] = (stats_df['thread_util_p99'] < 0) | (stats_df['thread_util_p99'] > 1.1)\n",
    "if 'vector_dim' in stats_df.columns:\n",
    "    flags['flag_vector_dim_nonpositive'] = stats_df['vector_dim'] <= 0\n",
    "if 'dataset_size' in stats_df.columns:\n",
    "    flags['flag_dataset_size_nonpositive'] = stats_df['dataset_size'] <= 0\n",
    "if 'num_queries' in stats_df.columns:\n",
    "    flags['flag_num_queries_nonpositive'] = stats_df['num_queries'] <= 0\n",
    "\n",
    "flags = flags.fillna(False)\n",
    "\n",
    "for col in flags.columns:\n",
    "    stats_df[col] = flags[col]\n",
    "\n",
    "exclude_any = flags.any(axis=1)\n",
    "filtered = stats_df[~exclude_any].copy()\n",
    "filtered_out = stats_df[exclude_any].copy()\n",
    "if not filtered_out.empty:\n",
    "    def build_reason(row):\n",
    "        return ','.join([c for c in flags.columns if row.get(c, False)])\n",
    "    filtered_out['exclude_reason'] = filtered_out.apply(build_reason, axis=1)\n",
    "\n",
    "print('filtered rows:', len(filtered))\n",
    "\n",
    "qc_summary = {\n",
    "    'total_rows': len(stats_df),\n",
    "    'filtered_rows': len(filtered),\n",
    "    'excluded_rows': int(exclude_any.sum()),\n",
    "    'low_recall_threshold': recall_threshold,\n",
    "}\n",
    "for col in flags.columns:\n",
    "    qc_summary[col] = int(flags[col].sum())\n",
    "\n",
    "qc_df = pd.DataFrame([qc_summary])\n",
    "qc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8dc737b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.357506Z",
     "iopub.status.busy": "2026-01-07T13:15:13.357433Z",
     "iopub.status.idle": "2026-01-07T13:15:13.563262Z",
     "shell.execute_reply": "2026-01-07T13:15:13.562921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_summary.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_basic_checks.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_missingness.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/filtered_stats.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/filtered_out_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Save QC outputs (basic)\n",
    "out_tables = (REPORT_DIR / 'tables')\n",
    "out_tables.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "qc_outputs = {\n",
    "    'qc_summary.csv': qc_df,\n",
    "    'qc_basic_checks.csv': qc_basic_df,\n",
    "    'qc_missingness.csv': missing_df,\n",
    "    'filtered_stats.csv': filtered,\n",
    "    'filtered_out_stats.csv': filtered_out,\n",
    "}\n",
    "\n",
    "for name, df in qc_outputs.items():\n",
    "    if df is None:\n",
    "        continue\n",
    "    df.to_csv(out_tables / name, index=False)\n",
    "    print('Saved:', out_tables / name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b3c4b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.564321Z",
     "iopub.status.busy": "2026-01-07T13:15:13.564253Z",
     "iopub.status.idle": "2026-01-07T13:15:13.586297Z",
     "shell.execute_reply": "2026-01-07T13:15:13.585930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rows</th>\n",
       "      <th>parse_ok_rows</th>\n",
       "      <th>parse_fail_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3150</td>\n",
       "      <td>3150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_rows  parse_ok_rows  parse_fail_rows\n",
       "0        3150           3150                0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse run_prefix and validate parameter consistency\n",
    "runprefix_parsed_df = pd.DataFrame()\n",
    "runprefix_mismatch_df = pd.DataFrame()\n",
    "runprefix_summary_df = pd.DataFrame()\n",
    "\n",
    "if 'run_prefix' in stats_df.columns:\n",
    "    parsed = stats_df['run_prefix'].apply(parse_run_prefix)\n",
    "    parsed_df = pd.DataFrame(list(parsed))\n",
    "    if not parsed_df.empty:\n",
    "        parsed_df = parsed_df.add_prefix('parsed_')\n",
    "        stats_df = pd.concat([stats_df, parsed_df], axis=1)\n",
    "        parse_ok = parsed_df.notna().any(axis=1)\n",
    "        runprefix_summary_df = pd.DataFrame([\n",
    "            {\n",
    "                'total_rows': len(stats_df),\n",
    "                'parse_ok_rows': int(parse_ok.sum()),\n",
    "                'parse_fail_rows': int((~parse_ok).sum()),\n",
    "            }\n",
    "        ])\n",
    "        mismatch_rows = []\n",
    "        for col in parsed_df.columns:\n",
    "            raw = col.replace('parsed_', '')\n",
    "            if raw in stats_df.columns:\n",
    "                left_series = stats_df[raw]\n",
    "                right_series = parsed_df[col]\n",
    "                # Prefer numeric comparison when both sides are numeric\n",
    "                left_num = pd.to_numeric(left_series, errors='coerce')\n",
    "                right_num = pd.to_numeric(right_series, errors='coerce')\n",
    "                both_numeric = left_num.notna() & right_num.notna()\n",
    "                mism_num = both_numeric & (left_num != right_num)\n",
    "                # Fallback to trimmed string comparison; ignore NaN on right\n",
    "                left_str = left_series.astype(str).str.strip()\n",
    "                right_str = right_series.astype(str).str.strip()\n",
    "                mism_str = (~both_numeric) & (right_str != 'nan') & (left_str != right_str)\n",
    "                mism = mism_num | mism_str\n",
    "                for idx in stats_df.index[mism]:\n",
    "                    mismatch_rows.append({\n",
    "                        'run_prefix': stats_df.loc[idx, 'run_prefix'],\n",
    "                        'field': raw,\n",
    "                        'stats_value': stats_df.loc[idx, raw],\n",
    "                        'parsed_value': parsed_df.loc[idx, col],\n",
    "                    })\n",
    "        runprefix_mismatch_df = pd.DataFrame(mismatch_rows)\n",
    "        runprefix_parsed_df = pd.concat([stats_df[['run_prefix']], parsed_df], axis=1)\n",
    "\n",
    "runprefix_summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e8d2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.587005Z",
     "iopub.status.busy": "2026-01-07T13:15:13.586946Z",
     "iopub.status.idle": "2026-01-07T13:15:13.983391Z",
     "shell.execute_reply": "2026-01-07T13:15:13.983117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>outlier_count</th>\n",
       "      <th>outlier_rate</th>\n",
       "      <th>median</th>\n",
       "      <th>mad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>iostat_w/s_max</td>\n",
       "      <td>1373</td>\n",
       "      <td>0.435873</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>iostat_wkB/s_max</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.372063</td>\n",
       "      <td>671.220000</td>\n",
       "      <td>84.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>iostat_rareq-sz_max</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.348254</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>iostat_w_await_max</td>\n",
       "      <td>955</td>\n",
       "      <td>0.303175</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>node_counts_top1_share</td>\n",
       "      <td>930</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>iostat_%rrqm_max</td>\n",
       "      <td>926</td>\n",
       "      <td>0.293968</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>io_us_max</td>\n",
       "      <td>924</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>4406.100100</td>\n",
       "      <td>2437.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>latency_max_us</td>\n",
       "      <td>924</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>4798.319350</td>\n",
       "      <td>2672.486800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>iostat_%wrqm_max</td>\n",
       "      <td>915</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>83.330000</td>\n",
       "      <td>7.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>iostat_r_await_max</td>\n",
       "      <td>868</td>\n",
       "      <td>0.275556</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column  outlier_count  outlier_rate       median  \\\n",
       "127          iostat_w/s_max           1373      0.435873     6.750000   \n",
       "133        iostat_wkB/s_max           1172      0.372063   671.220000   \n",
       "121     iostat_rareq-sz_max           1097      0.348254     4.040000   \n",
       "129      iostat_w_await_max            955      0.303175     3.500000   \n",
       "107  node_counts_top1_share            930      0.295238     0.009509   \n",
       "109        iostat_%rrqm_max            926      0.293968     1.005000   \n",
       "40                io_us_max            924      0.293333  4406.100100   \n",
       "27           latency_max_us            924      0.293333  4798.319350   \n",
       "113        iostat_%wrqm_max            915      0.290476    83.330000   \n",
       "119      iostat_r_await_max            868      0.275556     0.150000   \n",
       "\n",
       "             mad  \n",
       "127     0.770000  \n",
       "133    84.330000  \n",
       "121     0.020000  \n",
       "129     0.070000  \n",
       "107     0.002453  \n",
       "109     0.625000  \n",
       "40   2437.202100  \n",
       "27   2672.486800  \n",
       "113     7.580000  \n",
       "119     0.010000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier detection and descriptive stats\n",
    "outlier_summary_df = pd.DataFrame()\n",
    "outlier_samples_df = pd.DataFrame()\n",
    "basic_stats_df = pd.DataFrame()\n",
    "\n",
    "numeric_cols = [c for c in stats_df.columns if pd.api.types.is_numeric_dtype(stats_df[c])]\n",
    "if numeric_cols:\n",
    "    stats_numeric = stats_df[numeric_cols]\n",
    "    basic_stats_df = stats_numeric.describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]).T\n",
    "    basic_stats_df['missing_rate'] = stats_numeric.isna().mean()\n",
    "    basic_stats_df['zero_count'] = (stats_numeric == 0).sum()\n",
    "\n",
    "    summary_rows = []\n",
    "    sample_rows = []\n",
    "    for col in numeric_cols:\n",
    "        series = stats_numeric[col].dropna()\n",
    "        if series.nunique() < 2:\n",
    "            continue\n",
    "        median = series.median()\n",
    "        mad = np.median(np.abs(series - median))\n",
    "        if mad <= 0:\n",
    "            continue\n",
    "        z = 0.6745 * (series - median) / mad\n",
    "        mask = z.abs() > QC_OUTLIER_Z\n",
    "        count = int(mask.sum())\n",
    "        if count:\n",
    "            summary_rows.append({\n",
    "                'column': col,\n",
    "                'outlier_count': count,\n",
    "                'outlier_rate': count / max(len(series), 1),\n",
    "                'median': median,\n",
    "                'mad': mad,\n",
    "            })\n",
    "            for idx in series.index[mask]:\n",
    "                sample_rows.append({\n",
    "                    'run_prefix': stats_df.loc[idx, 'run_prefix'] if 'run_prefix' in stats_df.columns else idx,\n",
    "                    'column': col,\n",
    "                    'value': stats_df.loc[idx, col],\n",
    "                    'robust_z': z.loc[idx],\n",
    "                })\n",
    "\n",
    "    outlier_summary_df = pd.DataFrame(summary_rows).sort_values('outlier_count', ascending=False)\n",
    "    outlier_samples_df = pd.DataFrame(sample_rows)\n",
    "\n",
    "outlier_summary_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2d9f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.984315Z",
     "iopub.status.busy": "2026-01-07T13:15:13.984245Z",
     "iopub.status.idle": "2026-01-07T13:15:13.986346Z",
     "shell.execute_reply": "2026-01-07T13:15:13.986191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [run_prefix]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Track missing run_prefix across stats/topk\n",
    "missing_in_topk_df = pd.DataFrame({'run_prefix': missing_in_topk})\n",
    "missing_in_stats_df = pd.DataFrame({'run_prefix': missing_in_stats})\n",
    "\n",
    "missing_in_topk_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa2d0a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:13.986905Z",
     "iopub.status.busy": "2026-01-07T13:15:13.986848Z",
     "iopub.status.idle": "2026-01-07T13:15:14.481964Z",
     "shell.execute_reply": "2026-01-07T13:15:14.481572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional QC plots\n",
    "if QC_PLOT:\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig_dir = (REPORT_DIR / 'figures')\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plot_cols = [\n",
    "        'recall_mean',\n",
    "        'latency_p99_us',\n",
    "        'latency_p999_us',\n",
    "        'io_us_p99',\n",
    "        'queue_depth_p99',\n",
    "        'expanded_revisit_ratio',\n",
    "        'node_counts_top10_share',\n",
    "    ]\n",
    "    plot_cols = [c for c in plot_cols if c in stats_df.columns]\n",
    "    for col in plot_cols:\n",
    "        series = stats_df[col].dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(series, bins=50, color='#4c78a8', alpha=0.8)\n",
    "        plt.title(col)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_dir / f'qc_hist_{col}.png', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    if 'recall_mean' in stats_df.columns and 'latency_p99_us' in stats_df.columns:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(stats_df['recall_mean'], stats_df['latency_p99_us'], s=10, alpha=0.6)\n",
    "        plt.xlabel('recall_mean')\n",
    "        plt.ylabel('latency_p99_us')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_dir / 'qc_scatter_recall_latency_p99.png', dpi=150)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64a3e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:14.482835Z",
     "iopub.status.busy": "2026-01-07T13:15:14.482708Z",
     "iopub.status.idle": "2026-01-07T13:15:14.538637Z",
     "shell.execute_reply": "2026-01-07T13:15:14.538378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_runprefix_parsed.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_runprefix_mismatch.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_runprefix_summary.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_basic_stats.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_outlier_summary.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_outlier_samples.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_missing_in_topk.csv\n",
      "Saved: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/qc_missing_in_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Save additional QC outputs\n",
    "extra_outputs = {\n",
    "    'qc_runprefix_parsed.csv': runprefix_parsed_df,\n",
    "    'qc_runprefix_mismatch.csv': runprefix_mismatch_df,\n",
    "    'qc_runprefix_summary.csv': runprefix_summary_df,\n",
    "    'qc_basic_stats.csv': basic_stats_df,\n",
    "    'qc_outlier_summary.csv': outlier_summary_df,\n",
    "    'qc_outlier_samples.csv': outlier_samples_df,\n",
    "    'qc_missing_in_topk.csv': missing_in_topk_df,\n",
    "    'qc_missing_in_stats.csv': missing_in_stats_df,\n",
    "}\n",
    "\n",
    "for name, df in extra_outputs.items():\n",
    "    if df is None:\n",
    "        continue\n",
    "    df.to_csv(out_tables / name, index=False)\n",
    "    print('Saved:', out_tables / name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
