{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b7ba1c",
   "metadata": {},
   "source": [
    "# 04 Surrogate Model (XGBoost / LightGBM)\n",
    "\n",
    "Train a simple model to predict log(latency_p99_us).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47b6395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:53:12.327801Z",
     "iopub.status.busy": "2026-01-01T15:53:12.327662Z",
     "iopub.status.idle": "2026-01-01T15:53:12.426170Z",
     "shell.execute_reply": "2026-01-01T15:53:12.425921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/collected_stats_exp01_20260101_235226.csv\n",
      "topk : /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/collected_topk_exp01_20260101_235226.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ANALYZE_DIR = Path('../outputFiles/analyze').resolve()\n",
    "REPORT_PREFIX = os.environ.get('REPORT_PREFIX', 'analysis_reports')\n",
    "REPORT_DIR = (Path('../outputFiles/analyze').resolve() / REPORT_PREFIX)\n",
    "STATS_CSV = None  # set to a specific file path if needed\n",
    "TOPK_CSV = None   # set to a specific file path if needed\n",
    "\n",
    "def pick_latest(pattern):\n",
    "    files = sorted(ANALYZE_DIR.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f'No files matched: {pattern}')\n",
    "    return files[-1]\n",
    "\n",
    "stats_path = Path(STATS_CSV) if STATS_CSV else pick_latest('collected_stats_*.csv')\n",
    "topk_path = Path(TOPK_CSV) if TOPK_CSV else pick_latest('collected_topk_*.csv')\n",
    "\n",
    "print('stats:', stats_path)\n",
    "print('topk :', topk_path)\n",
    "\n",
    "stats_df = pd.read_csv(stats_path)\n",
    "topk_df = pd.read_csv(topk_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b475f63d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:53:12.426968Z",
     "iopub.status.busy": "2026-01-01T15:53:12.426891Z",
     "iopub.status.idle": "2026-01-01T15:53:12.820839Z",
     "shell.execute_reply": "2026-01-01T15:53:12.820510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (log latency p99): 0.09281692950447448\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df = stats_df.copy()\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['latency_p99_us'])\n",
    "df['log_latency_p99'] = np.log(df['latency_p99_us'].clip(lower=1))\n",
    "\n",
    "features = [\n",
    "    'build_R','build_L','build_B','build_M',\n",
    "    'search_K','search_L','search_W','search_T',\n",
    "    'vector_dim','dataset_size',\n",
    "    'out_degree_p99','expanded_revisit_ratio','node_counts_top10_share',\n",
    "    'iostat_aqu-sz_mean',\n",
    "]\n",
    "features = [f for f in features if f in df.columns]\n",
    "\n",
    "X = df[features]\n",
    "y = df['log_latency_p99']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = None\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print('xgboost not available:', e)\n",
    "\n",
    "if model is None:\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print('MAE (log latency p99):', mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
