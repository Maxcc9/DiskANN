{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b7ba1c",
   "metadata": {},
   "source": [
    "# 04 Surrogate Model (XGBoost / LightGBM)\n",
    "\n",
    "Train a simple model to predict log(latency_p99_us).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43029ff",
   "metadata": {},
   "source": [
    "# 說明\n",
    "\n",
    "本 notebook 訓練 surrogate model（XGBoost/RandomForest）預測延遲指標，輸出重要特徵與殘差分析。\n",
    "\n",
    "## 主要輸入\n",
    "- `tables/filtered_stats.csv`\n",
    "\n",
    "## 主要輸出\n",
    "- `tables/model_metrics.csv`\n",
    "- `tables/model_feature_importance_*.csv`\n",
    "- `tables/model_residual_summary.csv`\n",
    "\n",
    "## 合理性檢查建議\n",
    "- `r2` 不應為明顯負值\n",
    "- `baseline_mae_raw` 應高於模型的 `mae_raw`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47b6395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:40.286560Z",
     "iopub.status.busy": "2026-01-07T13:15:40.286428Z",
     "iopub.status.idle": "2026-01-07T13:15:40.425965Z",
     "shell.execute_reply": "2026-01-07T13:15:40.425685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/collected_stats_sift01_20260107_195000.csv\n",
      "topk : /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/collected_topk_sift01_20260107_195000.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ANALYZE_DIR = Path('../outputFiles/analyze').resolve()\n",
    "REPORT_PREFIX = os.environ.get('REPORT_PREFIX', 'analysis_reports')\n",
    "COLLECT_PREFIX = os.environ.get('COLLECT_PREFIX', REPORT_PREFIX)\n",
    "REPORT_DIR = (ANALYZE_DIR / REPORT_PREFIX)\n",
    "COLLECT_DIR = (ANALYZE_DIR / COLLECT_PREFIX)\n",
    "STATS_CSV = None  # set to a specific file path if needed\n",
    "TOPK_CSV = None   # set to a specific file path if needed\n",
    "\n",
    "FILTER_SEARCH_K = os.environ.get('FILTER_SEARCH_K', '27')\n",
    "TARGET_COLS = [\n",
    "    'latency_p99_us',\n",
    "    'latency_p95_us',\n",
    "    'latency_p50_us',\n",
    "    'mean_latency_us',\n",
    "]\n",
    "LOG_TARGETS = True\n",
    "TEST_SIZE = float(os.environ.get('MODEL_TEST_SIZE', '0.2'))\n",
    "RANDOM_STATE = int(os.environ.get('MODEL_RANDOM_STATE', '42'))\n",
    "\n",
    "FEATURE_CANDIDATES = [\n",
    "    'build_R','build_L','build_B','build_M',\n",
    "    'search_K','search_L','search_W','search_T','cache_size',\n",
    "    'vector_dim','dataset_size',\n",
    "    'out_degree_p99','out_degree_p95','out_degree_p50','out_degree_mean',\n",
    "    'expanded_revisit_ratio','expanded_per_query_mean','expanded_steps_mean',\n",
    "    'node_counts_top10_share','node_counts_top100_share',\n",
    "    'iostat_aqu-sz_mean','iostat_%util_mean','queue_depth_p99',\n",
    "    'io_us_p99','cpu_us_p99','thread_util_p99',\n",
    "]\n",
    "\n",
    "def pick_latest(pattern):\n",
    "    files = sorted(COLLECT_DIR.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f'No files matched: {pattern}')\n",
    "    return files[-1]\n",
    "\n",
    "def apply_search_k_filter(df, value):\n",
    "    if not value or 'search_K' not in df.columns:\n",
    "        return df\n",
    "    try:\n",
    "        target = int(value)\n",
    "    except ValueError:\n",
    "        return df\n",
    "    return df[df['search_K'] == target].copy()\n",
    "\n",
    "stats_path = Path(STATS_CSV) if STATS_CSV else pick_latest('collected_stats_*.csv')\n",
    "topk_path = Path(TOPK_CSV) if TOPK_CSV else pick_latest('collected_topk_*.csv')\n",
    "\n",
    "print('stats:', stats_path)\n",
    "print('topk :', topk_path)\n",
    "\n",
    "stats_df = pd.read_csv(stats_path)\n",
    "topk_df = pd.read_csv(topk_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b475f63d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:40.426875Z",
     "iopub.status.busy": "2026-01-07T13:15:40.426759Z",
     "iopub.status.idle": "2026-01-07T13:15:42.412388Z",
     "shell.execute_reply": "2026-01-07T13:15:42.412070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/filtered_stats.csv\n",
      "rows: 1380\n",
      "features: ['build_R', 'build_L', 'build_B', 'build_M', 'search_K', 'search_L', 'search_W', 'search_T', 'vector_dim', 'dataset_size', 'out_degree_p99', 'out_degree_p95', 'out_degree_p50', 'out_degree_mean', 'expanded_revisit_ratio', 'expanded_per_query_mean', 'expanded_steps_mean', 'node_counts_top10_share', 'node_counts_top100_share', 'iostat_aqu-sz_mean', 'iostat_%util_mean', 'queue_depth_p99', 'io_us_p99', 'cpu_us_p99', 'thread_util_p99']\n",
      "targets: ['latency_p99_us', 'latency_p95_us', 'latency_p50_us', 'mean_latency_us']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>rows</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>baseline_mae</th>\n",
       "      <th>mae_raw</th>\n",
       "      <th>rmse_raw</th>\n",
       "      <th>r2_raw</th>\n",
       "      <th>baseline_mae_raw</th>\n",
       "      <th>log_target</th>\n",
       "      <th>feature_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latency_p99_us</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.608870</td>\n",
       "      <td>27.434358</td>\n",
       "      <td>46.656382</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>1164.723936</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>latency_p95_us</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.998292</td>\n",
       "      <td>0.597401</td>\n",
       "      <td>35.024135</td>\n",
       "      <td>59.758135</td>\n",
       "      <td>0.997632</td>\n",
       "      <td>961.152484</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latency_p50_us</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.035708</td>\n",
       "      <td>0.080076</td>\n",
       "      <td>0.986423</td>\n",
       "      <td>0.605555</td>\n",
       "      <td>49.149794</td>\n",
       "      <td>120.200864</td>\n",
       "      <td>0.983874</td>\n",
       "      <td>716.351357</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_latency_us</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>0.044460</td>\n",
       "      <td>0.995524</td>\n",
       "      <td>0.591246</td>\n",
       "      <td>36.085281</td>\n",
       "      <td>67.502916</td>\n",
       "      <td>0.994205</td>\n",
       "      <td>692.583709</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  rows       mae      rmse        r2  baseline_mae  \\\n",
       "0   latency_p99_us  1380  0.015051  0.025990  0.998586      0.608870   \n",
       "1   latency_p95_us  1380  0.019122  0.027884  0.998292      0.597401   \n",
       "2   latency_p50_us  1380  0.035708  0.080076  0.986423      0.605555   \n",
       "3  mean_latency_us  1380  0.027634  0.044460  0.995524      0.591246   \n",
       "\n",
       "     mae_raw    rmse_raw    r2_raw  baseline_mae_raw  log_target  \\\n",
       "0  27.434358   46.656382  0.999001       1164.723936        True   \n",
       "1  35.024135   59.758135  0.997632        961.152484        True   \n",
       "2  49.149794  120.200864  0.983874        716.351357        True   \n",
       "3  36.085281   67.502916  0.994205        692.583709        True   \n",
       "\n",
       "   feature_count  \n",
       "0             25  \n",
       "1             25  \n",
       "2             25  \n",
       "3             25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Load filtered dataset if available\n",
    "filtered_path = (REPORT_DIR / 'tables' / 'filtered_stats.csv')\n",
    "filtered_df = None\n",
    "if filtered_path.exists():\n",
    "    filtered_df = pd.read_csv(filtered_path)\n",
    "    print('filtered:', filtered_path)\n",
    "else:\n",
    "    print('filtered not found:', filtered_path)\n",
    "\n",
    "base_df = filtered_df if filtered_df is not None else stats_df\n",
    "base_df = apply_search_k_filter(base_df, FILTER_SEARCH_K)\n",
    "\n",
    "feature_cols = [c for c in FEATURE_CANDIDATES if c in base_df.columns]\n",
    "target_cols = [c for c in TARGET_COLS if c in base_df.columns]\n",
    "\n",
    "print('rows:', len(base_df))\n",
    "print('features:', feature_cols)\n",
    "print('targets:', target_cols)\n",
    "\n",
    "out_tables = (REPORT_DIR / 'tables')\n",
    "out_tables.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metrics_rows = []\n",
    "all_predictions = []\n",
    "\n",
    "if not feature_cols or not target_cols:\n",
    "    print('Skip model training: missing features or targets')\n",
    "else:\n",
    "    for target in target_cols:\n",
    "        df = base_df.replace([np.inf, -np.inf], np.nan).dropna(subset=feature_cols + [target]).copy()\n",
    "        if len(df) < 20:\n",
    "            print('Skip target due to insufficient rows:', target)\n",
    "            continue\n",
    "\n",
    "        X = df[feature_cols]\n",
    "        y_raw = df[target]\n",
    "        if LOG_TARGETS and target.endswith('_us'):\n",
    "            y = np.log(y_raw.clip(lower=1))\n",
    "        else:\n",
    "            y = y_raw\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        model = None\n",
    "        try:\n",
    "            import xgboost as xgb\n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=300,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=RANDOM_STATE,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print('xgboost not available:', e)\n",
    "\n",
    "        if model is None:\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            model = RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "        r2 = r2_score(y_test, pred)\n",
    "        baseline = np.median(y_train)\n",
    "        baseline_mae = mean_absolute_error(y_test, np.full_like(y_test, baseline))\n",
    "\n",
    "        if LOG_TARGETS and target.endswith('_us'):\n",
    "            y_test_raw = np.exp(y_test)\n",
    "            pred_raw = np.exp(pred)\n",
    "            baseline_raw = np.median(np.exp(y_train))\n",
    "        else:\n",
    "            y_test_raw = y_test\n",
    "            pred_raw = pred\n",
    "            baseline_raw = np.median(y_train)\n",
    "\n",
    "        mae_raw = mean_absolute_error(y_test_raw, pred_raw)\n",
    "        rmse_raw = np.sqrt(mean_squared_error(y_test_raw, pred_raw))\n",
    "        r2_raw = r2_score(y_test_raw, pred_raw)\n",
    "        baseline_mae_raw = mean_absolute_error(y_test_raw, np.full_like(y_test_raw, baseline_raw))\n",
    "\n",
    "        metrics_rows.append({\n",
    "            'target': target,\n",
    "            'rows': len(df),\n",
    "            'mae': float(mae),\n",
    "            'rmse': float(rmse),\n",
    "            'r2': float(r2),\n",
    "            'baseline_mae': float(baseline_mae),\n",
    "            'mae_raw': float(mae_raw),\n",
    "            'rmse_raw': float(rmse_raw),\n",
    "            'r2_raw': float(r2_raw),\n",
    "            'baseline_mae_raw': float(baseline_mae_raw),\n",
    "            'log_target': bool(LOG_TARGETS and target.endswith('_us')),\n",
    "            'feature_count': len(feature_cols),\n",
    "        })\n",
    "\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            fi = pd.DataFrame({\n",
    "                'feature': feature_cols,\n",
    "                'importance': model.feature_importances_,\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            fi.to_csv(out_tables / f'model_feature_importance_{target}.csv', index=False)\n",
    "\n",
    "        try:\n",
    "            perm = permutation_importance(model, X_test, y_test, n_repeats=8, random_state=RANDOM_STATE)\n",
    "            perm_df = pd.DataFrame({\n",
    "                'feature': feature_cols,\n",
    "                'importance_mean': perm.importances_mean,\n",
    "                'importance_std': perm.importances_std,\n",
    "            }).sort_values('importance_mean', ascending=False)\n",
    "            perm_df.to_csv(out_tables / f'model_permutation_importance_{target}.csv', index=False)\n",
    "        except Exception as e:\n",
    "            print('Permutation importance failed:', e)\n",
    "\n",
    "        full_pred = model.predict(X)\n",
    "        if LOG_TARGETS and target.endswith('_us'):\n",
    "            full_pred_raw = np.exp(full_pred)\n",
    "            y_true_model = np.log(y_raw.clip(lower=1))\n",
    "        else:\n",
    "            full_pred_raw = full_pred\n",
    "            y_true_model = y_raw.values\n",
    "        pred_df = pd.DataFrame({\n",
    "            'run_prefix': df['run_prefix'] if 'run_prefix' in df.columns else df.index,\n",
    "            'target': target,\n",
    "            'y_true_raw': y_raw.values,\n",
    "            'y_pred_raw': full_pred_raw,\n",
    "            'y_true_model': y_true_model,\n",
    "            'y_pred_model': full_pred,\n",
    "        })\n",
    "        pred_df.to_csv(out_tables / f'model_predictions_{target}.csv', index=False)\n",
    "        all_predictions.append(pred_df)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "if not metrics_df.empty:\n",
    "    metrics_df.to_csv(out_tables / 'model_metrics.csv', index=False)\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8c69c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:42.413377Z",
     "iopub.status.busy": "2026-01-07T13:15:42.413277Z",
     "iopub.status.idle": "2026-01-07T13:15:42.428069Z",
     "shell.execute_reply": "2026-01-07T13:15:42.427824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>mae</th>\n",
       "      <th>p50_abs_error</th>\n",
       "      <th>p90_abs_error</th>\n",
       "      <th>p99_abs_error</th>\n",
       "      <th>error_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latency_p99_us</td>\n",
       "      <td>10.600035</td>\n",
       "      <td>4.948380</td>\n",
       "      <td>24.80414</td>\n",
       "      <td>91.527895</td>\n",
       "      <td>raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>latency_p95_us</td>\n",
       "      <td>14.204070</td>\n",
       "      <td>5.865815</td>\n",
       "      <td>32.11756</td>\n",
       "      <td>141.989962</td>\n",
       "      <td>raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latency_p50_us</td>\n",
       "      <td>16.953303</td>\n",
       "      <td>5.938140</td>\n",
       "      <td>36.00894</td>\n",
       "      <td>165.058717</td>\n",
       "      <td>raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_latency_us</td>\n",
       "      <td>13.730007</td>\n",
       "      <td>5.999900</td>\n",
       "      <td>29.94640</td>\n",
       "      <td>133.131040</td>\n",
       "      <td>raw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target        mae  p50_abs_error  p90_abs_error  p99_abs_error  \\\n",
       "0   latency_p99_us  10.600035       4.948380       24.80414      91.527895   \n",
       "1   latency_p95_us  14.204070       5.865815       32.11756     141.989962   \n",
       "2   latency_p50_us  16.953303       5.938140       36.00894     165.058717   \n",
       "3  mean_latency_us  13.730007       5.999900       29.94640     133.131040   \n",
       "\n",
       "  error_space  \n",
       "0         raw  \n",
       "1         raw  \n",
       "2         raw  \n",
       "3         raw  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual analysis\n",
    "import pandas as pd\n",
    "residual_rows = []\n",
    "worst_rows = []\n",
    "if 'metrics_df' in globals() and not metrics_df.empty:\n",
    "    for target in metrics_df['target']:\n",
    "        pred_path = out_tables / f'model_predictions_{target}.csv'\n",
    "        if not pred_path.exists():\n",
    "            continue\n",
    "        pred_df = pd.read_csv(pred_path)\n",
    "        if 'y_true_raw' in pred_df.columns and 'y_pred_raw' in pred_df.columns:\n",
    "            pred_df['abs_error'] = (pred_df['y_true_raw'] - pred_df['y_pred_raw']).abs()\n",
    "            error_label = 'raw'\n",
    "        else:\n",
    "            pred_df['abs_error'] = (pred_df['y_true_model'] - pred_df['y_pred_model']).abs()\n",
    "            error_label = 'model'\n",
    "        residual_rows.append({\n",
    "            'target': target,\n",
    "            'mae': pred_df['abs_error'].mean(),\n",
    "            'p50_abs_error': pred_df['abs_error'].median(),\n",
    "            'p90_abs_error': pred_df['abs_error'].quantile(0.9),\n",
    "            'p99_abs_error': pred_df['abs_error'].quantile(0.99),\n",
    "            'error_space': error_label,\n",
    "        })\n",
    "        worst = pred_df.sort_values('abs_error', ascending=False).head(20)\n",
    "        worst['target'] = target\n",
    "        worst_rows.append(worst)\n",
    "\n",
    "residual_df = pd.DataFrame(residual_rows)\n",
    "if not residual_df.empty:\n",
    "    residual_df.to_csv(out_tables / 'model_residual_summary.csv', index=False)\n",
    "\n",
    "if worst_rows:\n",
    "    worst_df = pd.concat(worst_rows, ignore_index=True)\n",
    "    worst_df.to_csv(out_tables / 'model_worst_residuals.csv', index=False)\n",
    "\n",
    "residual_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
