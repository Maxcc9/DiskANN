{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead5bfab",
   "metadata": {},
   "source": [
    "# 05 SHAP Explainability\n",
    "\n",
    "Compute SHAP values for the surrogate model if SHAP is available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c2870",
   "metadata": {},
   "source": [
    "# 說明\n",
    "\n",
    "本 notebook 透過 SHAP 解釋 surrogate model 的特徵影響，輸出 summary/bar 與 dependence plot。\n",
    "\n",
    "## 主要輸入\n",
    "- `tables/filtered_stats.csv`\n",
    "\n",
    "## 主要輸出\n",
    "- `figures/shap_summary_*.png`\n",
    "- `tables/shap_mean_abs_*.csv`\n",
    "\n",
    "## 合理性檢查建議\n",
    "- SHAP 重要度應與 model feature importance 大致一致\n",
    "- 若 SHAP 缺少輸出，確認環境安裝了 `xgboost` 與 `shap`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171b88ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:15:43.486917Z",
     "iopub.status.busy": "2026-01-07T13:15:43.486831Z",
     "iopub.status.idle": "2026-01-07T13:15:48.837036Z",
     "shell.execute_reply": "2026-01-07T13:15:48.836767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered: /home/gt/research/DiskANN/scripts/paramAnalysis/gridSearch/outputFiles/analyze/sift01/tables/filtered_stats.csv\n",
      "rows: 1380\n",
      "features: ['build_R', 'build_L', 'build_B', 'build_M', 'search_K', 'search_L', 'search_W', 'search_T', 'vector_dim', 'dataset_size', 'out_degree_p99', 'out_degree_p95', 'out_degree_p50', 'out_degree_mean', 'expanded_revisit_ratio', 'expanded_per_query_mean', 'expanded_steps_mean', 'node_counts_top10_share', 'node_counts_top100_share', 'iostat_aqu-sz_mean', 'iostat_%util_mean', 'queue_depth_p99', 'io_us_p99', 'cpu_us_p99', 'thread_util_p99']\n",
      "targets: ['latency_p99_us', 'latency_p95_us', 'latency_p50_us', 'mean_latency_us']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP outputs for latency_p99_us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP outputs for latency_p95_us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP outputs for latency_p50_us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP outputs for mean_latency_us\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ANALYZE_DIR = Path('../outputFiles/analyze').resolve()\n",
    "REPORT_PREFIX = os.environ.get('REPORT_PREFIX', 'analysis_reports')\n",
    "COLLECT_PREFIX = os.environ.get('COLLECT_PREFIX', REPORT_PREFIX)\n",
    "REPORT_DIR = (ANALYZE_DIR / REPORT_PREFIX)\n",
    "COLLECT_DIR = (ANALYZE_DIR / COLLECT_PREFIX)\n",
    "\n",
    "FILTER_SEARCH_K = os.environ.get('FILTER_SEARCH_K', '10')\n",
    "TARGET_COLS = [\n",
    "    'latency_p99_us',\n",
    "    'latency_p95_us',\n",
    "    'latency_p50_us',\n",
    "    'mean_latency_us',\n",
    "]\n",
    "LOG_TARGETS = True\n",
    "MAX_SAMPLES = int(os.environ.get('SHAP_MAX_SAMPLES', '2000'))\n",
    "\n",
    "FEATURE_CANDIDATES = [\n",
    "    'build_R','build_L','build_B','build_M',\n",
    "    'search_K','search_L','search_W','search_T','cache_size',\n",
    "    'vector_dim','dataset_size',\n",
    "    'out_degree_p99','out_degree_p95','out_degree_p50','out_degree_mean',\n",
    "    'expanded_revisit_ratio','expanded_per_query_mean','expanded_steps_mean',\n",
    "    'node_counts_top10_share','node_counts_top100_share',\n",
    "    'iostat_aqu-sz_mean','iostat_%util_mean','queue_depth_p99',\n",
    "    'io_us_p99','cpu_us_p99','thread_util_p99',\n",
    "]\n",
    "\n",
    "def apply_search_k_filter(df, value):\n",
    "    if not value or 'search_K' not in df.columns:\n",
    "        return df\n",
    "    try:\n",
    "        target = int(value)\n",
    "    except ValueError:\n",
    "        return df\n",
    "    return df[df['search_K'] == target].copy()\n",
    "\n",
    "stats_path = sorted(COLLECT_DIR.glob('collected_stats_*.csv'))[-1]\n",
    "stats_df = pd.read_csv(stats_path)\n",
    "\n",
    "filtered_path = (REPORT_DIR / 'tables' / 'filtered_stats.csv')\n",
    "filtered_df = None\n",
    "if filtered_path.exists():\n",
    "    filtered_df = pd.read_csv(filtered_path)\n",
    "    print('filtered:', filtered_path)\n",
    "else:\n",
    "    print('filtered not found:', filtered_path)\n",
    "\n",
    "base_df = filtered_df if filtered_df is not None else stats_df\n",
    "base_df = apply_search_k_filter(base_df, FILTER_SEARCH_K)\n",
    "\n",
    "feature_cols = [c for c in FEATURE_CANDIDATES if c in base_df.columns]\n",
    "target_cols = [c for c in TARGET_COLS if c in base_df.columns]\n",
    "\n",
    "print('rows:', len(base_df))\n",
    "print('features:', feature_cols)\n",
    "print('targets:', target_cols)\n",
    "\n",
    "out_fig = (REPORT_DIR / 'figures')\n",
    "out_tbl = (REPORT_DIR / 'tables')\n",
    "out_fig.mkdir(parents=True, exist_ok=True)\n",
    "out_tbl.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    import shap\n",
    "except Exception as e:\n",
    "    print('SHAP or xgboost not available:', e)\n",
    "    xgb = None\n",
    "    shap = None\n",
    "\n",
    "if xgb is None or shap is None or not feature_cols or not target_cols:\n",
    "    print('Skip SHAP analysis due to missing deps or columns')\n",
    "else:\n",
    "    for target in target_cols:\n",
    "        df = base_df.replace([np.inf, -np.inf], np.nan).dropna(subset=feature_cols + [target]).copy()\n",
    "        if len(df) < 50:\n",
    "            print('Skip target due to insufficient rows:', target)\n",
    "            continue\n",
    "\n",
    "        X = df[feature_cols]\n",
    "        y_raw = df[target]\n",
    "        if LOG_TARGETS and target.endswith('_us'):\n",
    "            y = np.log(y_raw.clip(lower=1))\n",
    "        else:\n",
    "            y = y_raw\n",
    "\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "        )\n",
    "        model.fit(X, y)\n",
    "\n",
    "        if len(X) > MAX_SAMPLES:\n",
    "            X_sample = X.sample(n=MAX_SAMPLES, random_state=42)\n",
    "        else:\n",
    "            X_sample = X\n",
    "\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "        shap.summary_plot(shap_values, X_sample, show=False)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_fig / f'shap_summary_{target}.png', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        shap.summary_plot(shap_values, X_sample, plot_type='bar', show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_fig / f'shap_bar_{target}.png', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        shap_df = pd.DataFrame(shap_values, columns=feature_cols)\n",
    "        shap_mean = shap_df.abs().mean().sort_values(ascending=False)\n",
    "        shap_mean.to_csv(out_tbl / f'shap_mean_abs_{target}.csv')\n",
    "\n",
    "        top_features = shap_mean.head(5).index.tolist()\n",
    "        for feat in top_features:\n",
    "            try:\n",
    "                shap.dependence_plot(feat, shap_values, X_sample, show=False)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(out_fig / f'shap_dependence_{target}_{feat}.png', dpi=150)\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print('dependence plot failed:', target, feat, e)\n",
    "\n",
    "        print('Saved SHAP outputs for', target)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
