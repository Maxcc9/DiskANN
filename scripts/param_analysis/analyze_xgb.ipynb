{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 導入必要套件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 設定顯示選項\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✓ 套件導入完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 載入聚合結果\n",
    "results_df = pd.read_csv('results_all.csv')\n",
    "print(f\"✓ 載入 {len(results_df)} 筆樣本\")\n",
    "print(f\"\\n欄位 ({len(results_df.columns)}):\")\n",
    "print(results_df.columns.tolist())\n",
    "print(f\"\\n前 3 筆資料:\")\n",
    "print(results_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 特徵工程：分離參數與測量指標\n",
    "\n",
    "# 可用的特徵候選（避免把目標欄位或識別欄位放入）\n",
    "candidate_features = [\n",
    "    'build_R', 'build_L', 'build_B', 'build_M',\n",
    "    'search_K', 'search_L', 'search_W', 'search_T', 'search_io_limit',\n",
    "    'num_queries', 'dataset_size', 'vector_dim', 'actual_cached_nodes'\n",
    "]\n",
    "\n",
    "# 僅保留存在且為數值的欄位\n",
    "feature_cols = [\n",
    "    c for c in candidate_features\n",
    "    if c in results_df.columns and pd.api.types.is_numeric_dtype(results_df[c])\n",
    "]\n",
    "X = results_df[feature_cols].copy()\n",
    "\n",
    "# 目標指標（排除名稱型欄位）\n",
    "target_metrics = {\n",
    "    # 基本性能\n",
    "    'qps': 'QPS (查詢/秒)',\n",
    "    'mean_latency_us': '平均延遲 (µs)',\n",
    "    'latency_p50_us': 'P50 延遲 (µs)',\n",
    "    'latency_p75_us': 'P75 延遲 (µs)',\n",
    "    'latency_p90_us': 'P90 延遲 (µs)',\n",
    "    'latency_p95_us': 'P95 延遲 (µs)',\n",
    "    'latency_p99_us': 'P99 延遲 (µs)',\n",
    "    'latency_p999_us': 'P99.9 延遲 (µs)',\n",
    "    'latency_max_us': '最大延遲 (µs)',\n",
    "\n",
    "    # IO 數量\n",
    "    'ios_mean': '平均 IO 數',\n",
    "    'ios_p50': 'IO P50',\n",
    "    'ios_p75': 'IO P75',\n",
    "    'ios_p90': 'IO P90',\n",
    "    'ios_p95': 'IO P95',\n",
    "    'ios_p99': 'IO P99',\n",
    "    'ios_max': 'IO 最大值',\n",
    "\n",
    "    # IO 時間\n",
    "    'io_us_mean': 'IO 平均時間 (µs)',\n",
    "    'io_us_p50': 'IO P50 (µs)',\n",
    "    'io_us_p75': 'IO P75 (µs)',\n",
    "    'io_us_p90': 'IO P90 (µs)',\n",
    "    'io_us_p95': 'IO P95 (µs)',\n",
    "    'io_us_p99': 'IO P99 (µs)',\n",
    "    'io_us_max': 'IO 最大值 (µs)',\n",
    "\n",
    "    # CPU 時間\n",
    "    'cpu_us_mean': 'CPU 平均時間 (µs)',\n",
    "    'cpu_us_p50': 'CPU P50 (µs)',\n",
    "    'cpu_us_p75': 'CPU P75 (µs)',\n",
    "    'cpu_us_p90': 'CPU P90 (µs)',\n",
    "    'cpu_us_p95': 'CPU P95 (µs)',\n",
    "    'cpu_us_p99': 'CPU P99 (µs)',\n",
    "    'cpu_us_max': 'CPU 最大值 (µs)',\n",
    "\n",
    "    # Sort 時間\n",
    "    'sort_us_mean': 'Sort 平均時間 (µs)',\n",
    "    'sort_us_p50': 'Sort P50 (µs)',\n",
    "    'sort_us_p75': 'Sort P75 (µs)',\n",
    "    'sort_us_p90': 'Sort P90 (µs)',\n",
    "    'sort_us_p95': 'Sort P95 (µs)',\n",
    "    'sort_us_p99': 'Sort P99 (µs)',\n",
    "    'sort_us_max': 'Sort 最大值 (µs)',\n",
    "\n",
    "    # 讀取量\n",
    "    'read_size_mean': '讀取量平均 (bytes)',\n",
    "    'read_size_p50': '讀取量 P50 (bytes)',\n",
    "    'read_size_p75': '讀取量 P75 (bytes)',\n",
    "    'read_size_p90': '讀取量 P90 (bytes)',\n",
    "    'read_size_p95': '讀取量 P95 (bytes)',\n",
    "    'read_size_p99': '讀取量 P99 (bytes)',\n",
    "    'read_size_max': '讀取量最大 (bytes)',\n",
    "\n",
    "    # 比較次數\n",
    "    'compares_mean': '比較次數平均',\n",
    "    'compares_p50': '比較次數 P50',\n",
    "    'compares_p75': '比較次數 P75',\n",
    "    'compares_p90': '比較次數 P90',\n",
    "    'compares_p95': '比較次數 P95',\n",
    "    'compares_p99': '比較次數 P99',\n",
    "    'compares_max': '比較次數最大',\n",
    "\n",
    "    # Recall\n",
    "    'recall_mean': 'Recall 平均',\n",
    "    'recall_p0': 'Recall P0',\n",
    "    'recall_p1': 'Recall P1',\n",
    "    'recall_p5': 'Recall P5',\n",
    "    'recall_p10': 'Recall P10',\n",
    "    'recall_p25': 'Recall P25',\n",
    "    'recall_p50': 'Recall P50',\n",
    "    'recall_p75': 'Recall P75',\n",
    "    'recall_p90': 'Recall P90',\n",
    "    'recall_max': 'Recall 最大',\n",
    "\n",
    "    # Cache hit rate\n",
    "    'cache_hit_rate_mean': 'Cache hit 平均',\n",
    "    'cache_hit_rate_p0': 'Cache hit P0',\n",
    "    'cache_hit_rate_p1': 'Cache hit P1',\n",
    "    'cache_hit_rate_p5': 'Cache hit P5',\n",
    "    'cache_hit_rate_p10': 'Cache hit P10',\n",
    "    'cache_hit_rate_p25': 'Cache hit P25',\n",
    "    'cache_hit_rate_p50': 'Cache hit P50',\n",
    "    'cache_hit_rate_p75': 'Cache hit P75',\n",
    "    'cache_hit_rate_p90': 'Cache hit P90',\n",
    "    'cache_hit_rate_max': 'Cache hit 最大',\n",
    "\n",
    "    # Hops / Visited\n",
    "    'hop_mean': 'Hop 平均',\n",
    "    'hop_p50': 'Hop P50',\n",
    "    'hop_p75': 'Hop P75',\n",
    "    'hop_p90': 'Hop P90',\n",
    "    'hop_p95': 'Hop P95',\n",
    "    'hop_p99': 'Hop P99',\n",
    "    'hop_max': 'Hop 最大',\n",
    "    'visited_mean': 'Visited 平均',\n",
    "    'visited_p50': 'Visited P50',\n",
    "    'visited_p75': 'Visited P75',\n",
    "    'visited_p90': 'Visited P90',\n",
    "    'visited_p95': 'Visited P95',\n",
    "    'visited_p99': 'Visited P99',\n",
    "    'visited_max': 'Visited 最大',\n",
    "\n",
    "    # Out degree (未來會有值)\n",
    "    'out_degree_mean': 'Out degree 平均',\n",
    "    'out_degree_p0': 'Out degree P0',\n",
    "    'out_degree_p1': 'Out degree P1',\n",
    "    'out_degree_p5': 'Out degree P5',\n",
    "    'out_degree_p10': 'Out degree P10',\n",
    "    'out_degree_p25': 'Out degree P25',\n",
    "    'out_degree_p50': 'Out degree P50',\n",
    "    'out_degree_p75': 'Out degree P75',\n",
    "    'out_degree_p90': 'Out degree P90',\n",
    "    'out_degree_p95': 'Out degree P95',\n",
    "    'out_degree_p99': 'Out degree P99',\n",
    "    'out_degree_max': 'Out degree 最大'\n",
    "}\n",
    "\n",
    "print(f\"✓ 特徵數量: {len(feature_cols)}\")\n",
    "print(f\"  特徵: {feature_cols}\")\n",
    "print(\"\")\n",
    "print(f\"✓ 目標指標數量: {len(target_metrics)}\")\n",
    "for metric, desc in target_metrics.items():\n",
    "    if metric in results_df.columns:\n",
    "        print(f\"  {metric:20s} ({desc})\")\n",
    "        print(f\"    範圍: [{results_df[metric].min():.4f}, {results_df[metric].max():.4f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22176983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 數據品質檢查\n",
    "print(\"=== 數據缺失檢查 ===\")\n",
    "cols_to_check = feature_cols + list(target_metrics.keys())\n",
    "if cols_to_check:\n",
    "    missing = results_df[cols_to_check].isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"\")\n",
    "        print(\"缺失欄位:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"✓ 無缺失值\")\n",
    "else:\n",
    "    print(\"⚠ 沒有可用欄位進行檢查\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"=== 特徵統計 ===\")\n",
    "if feature_cols:\n",
    "    print(X.describe())\n",
    "else:\n",
    "    print(\"⚠ 沒有可用特徵\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d035b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 訓練多個 XGBoost 模型\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"開始訓練 XGBoost 模型\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models = {}  # 儲存訓練好的模型\n",
    "cv_scores = {}  # 交叉驗證分數\n",
    "\n",
    "for metric, metric_name in target_metrics.items():\n",
    "    if metric not in results_df.columns:\n",
    "        print(f\"⚠ 跳過 {metric} (資料不存在)\")\n",
    "        continue\n",
    "    \n",
    "    y = results_df[metric].values\n",
    "    \n",
    "    # 處理任何 NaN 或無效值\n",
    "    valid_idx = ~np.isnan(y) & np.isfinite(y)\n",
    "    X_valid = X[valid_idx]\n",
    "    y_valid = y[valid_idx]\n",
    "    \n",
    "    if len(y_valid) < 10:\n",
    "        print(f\"⚠ {metric}: 有效樣本過少 ({len(y_valid)})，跳過\")\n",
    "        continue\n",
    "    \n",
    "    # 訓練模型\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # 交叉驗證\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_r2 = cross_val_score(model, X_valid, y_valid, cv=kfold, scoring='r2')\n",
    "    cv_rmse = -cross_val_score(model, X_valid, y_valid, cv=kfold, scoring='neg_root_mean_squared_error')\n",
    "    \n",
    "    # 在全部資料上訓練（用於 SHAP）\n",
    "    model.fit(X_valid, y_valid)\n",
    "    \n",
    "    models[metric] = model\n",
    "    cv_scores[metric] = {'r2': cv_r2, 'rmse': cv_rmse}\n",
    "    \n",
    "    print(f\"\\n✓ {metric_name}\")\n",
    "    print(f\"  有效樣本: {len(y_valid)}\")\n",
    "    print(f\"  R² (5-fold): {cv_r2.mean():.4f} ± {cv_r2.std():.4f}\")\n",
    "    print(f\"  RMSE (5-fold): {cv_rmse.mean():.4f} ± {cv_rmse.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 特徵重要性分析\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBoost 內建特徵重要性\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "feature_importance_all = {}\n",
    "\n",
    "for metric, model in models.items():\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    feature_importance_all[metric] = importance\n",
    "    \n",
    "    print(f\"\\n{metric}:\")\n",
    "    for _, row in importance.iterrows():\n",
    "        bar = '█' * int(row['importance'] * 50)\n",
    "        print(f\"  {row['feature']:20s} {bar} {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f46d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. SHAP 特徵重要性分析\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SHAP 特徵重要性 (TreeExplainer)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "shap_values_all = {}\n",
    "\n",
    "for metric, model in models.items():\n",
    "    # 取得有效資料\n",
    "    y = results_df[metric].values\n",
    "    valid_idx = ~np.isnan(y) & np.isfinite(y)\n",
    "    X_valid = X[valid_idx]\n",
    "    \n",
    "    # 計算 SHAP 值\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_valid)\n",
    "    shap_values_all[metric] = (shap_values, X_valid, explainer)\n",
    "    \n",
    "    # 計算平均 |SHAP| 作為特徵重要性\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'mean_abs_shap': mean_abs_shap\n",
    "    }).sort_values('mean_abs_shap', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{metric}:\")\n",
    "    for _, row in shap_importance.iterrows():\n",
    "        bar = '█' * int(row['mean_abs_shap'] * 100)\n",
    "        print(f\"  {row['feature']:20s} {bar} {row['mean_abs_shap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. SHAP 摘要圖\n",
    "print(\"\\n生成 SHAP 摘要圖...\")\n",
    "\n",
    "# 只對前 3 個指標繪圖（避免太多圖表）\n",
    "metrics_to_plot = list(models.keys())[:3]\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    shap_values, X_valid, explainer = shap_values_all[metric]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_valid, plot_type='bar', show=False)\n",
    "    plt.title(f\"SHAP Feature Importance - {metric}\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "print(\"✓ SHAP 圖表完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. SHAP 依賴圖（最重要的 2 個特徵）\n",
    "print(\"\\n生成 SHAP 依賴圖...\")\n",
    "\n",
    "for metric in metrics_to_plot:\n",
    "    shap_values, X_valid, explainer = shap_values_all[metric]\n",
    "    \n",
    "    # 計算特徵重要性排名\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    top_2_features = np.argsort(mean_abs_shap)[-2:][::-1]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    for idx, feat_idx in enumerate(top_2_features):\n",
    "        shap.dependence_plot(\n",
    "            feat_idx, shap_values, X_valid,\n",
    "            feature_names=feature_cols,\n",
    "            ax=axes[idx],\n",
    "            show=False\n",
    "        )\n",
    "        axes[idx].set_title(f\"{metric} - {feature_cols[feat_idx]}\", fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f\"SHAP 依賴圖 - {metric}\", fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ 依賴圖完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1276d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 預測 vs 實際比較\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"模型預測準確度\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric, model in models.items():\n",
    "    y = results_df[metric].values\n",
    "    valid_idx = ~np.isnan(y) & np.isfinite(y)\n",
    "    X_valid = X[valid_idx]\n",
    "    y_valid = y[valid_idx]\n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "    mae = mean_absolute_error(y_valid, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "    \n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"  R² 分數: {r2:.4f}\")\n",
    "    print(f\"  平均絕對誤差 (MAE): {mae:.4f}\")\n",
    "    print(f\"  均方根誤差 (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. 參數敏感度排序總結\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"參數敏感度排序 (跨所有指標)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 聚合所有指標的特徵重要性\n",
    "aggregated_importance = {feat: [] for feat in feature_cols}\n",
    "\n",
    "for metric, model in models.items():\n",
    "    importance_dict = dict(zip(feature_cols, model.feature_importances_))\n",
    "    for feat in feature_cols:\n",
    "        aggregated_importance[feat].append(importance_dict[feat])\n",
    "\n",
    "# 計算平均重要性\n",
    "avg_importance = {feat: np.mean(values) for feat, values in aggregated_importance.items()}\n",
    "sorted_importance = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n平均特徵重要性排名 (XGBoost):\")\n",
    "for rank, (feat, imp) in enumerate(sorted_importance, 1):\n",
    "    bar = '█' * int(imp * 50)\n",
    "    print(f\"  {rank}. {feat:20s} {bar} {imp:.4f}\")\n",
    "\n",
    "# 計算 SHAP 平均重要性\n",
    "print(\"\\n平均特徵重要性排名 (SHAP):\")\n",
    "aggregated_shap = {feat: [] for feat in feature_cols}\n",
    "\n",
    "for metric, (shap_values, X_valid, _) in shap_values_all.items():\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    for feat_idx, feat in enumerate(feature_cols):\n",
    "        aggregated_shap[feat].append(mean_abs_shap[feat_idx])\n",
    "\n",
    "avg_shap = {feat: np.mean(values) for feat, values in aggregated_shap.items()}\n",
    "sorted_shap = sorted(avg_shap.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (feat, imp) in enumerate(sorted_shap, 1):\n",
    "    bar = '█' * int(imp * 100)\n",
    "    print(f\"  {rank}. {feat:20s} {bar} {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 結論與建議\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"分析結論\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "✓ XGBoost 模型成功訓練完成\n",
    "  - 模型使用 5-fold 交叉驗證評估\n",
    "  - SHAP 值解釋模型決策過程\n",
    "\n",
    "主要發現:\n",
    "1. 特徵重要性排名顯示了各參數對性能的影響\n",
    "2. SHAP 依賴圖揭示了參數與指標的非線性關係\n",
    "3. 交叉驗證分數評估了模型的泛化能力\n",
    "\n",
    "建議:\n",
    "- 優化排名靠前的參數以提升性能\n",
    "- 考慮參數間的交互作用（可通過 SHAP 分析）\n",
    "- 在實際應用中驗證模型預測\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✓ 分析完成！\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
